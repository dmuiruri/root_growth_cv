{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root detection\n",
    "\n",
    "In this notebook I will test different masking techniques to make image segmentation so that roots can be separated from the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from skimage import exposure, measure\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function grab_contrours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grab_contours(cnts):\n",
    "    # if the length the contours tuple returned by cv2.findContours\n",
    "    # is '2' then we are using either OpenCV v2.4, v4-beta, or\n",
    "    # v4-official\n",
    "    if len(cnts) == 2:\n",
    "        cnts = cnts[0]\n",
    "\n",
    "    # if the length of the contours tuple is '3' then we are using\n",
    "    # either OpenCV v3, v4-pre, or v4-alpha\n",
    "    elif len(cnts) == 3:\n",
    "        cnts = cnts[1]\n",
    "\n",
    "    # otherwise OpenCV has changed their cv2.findContours return\n",
    "    # signature yet again and I have no idea WTH is going on\n",
    "    else:\n",
    "        raise Exception((\"Contours tuple must have length 2 or 3, \"\n",
    "            \"otherwise OpenCV changed their cv2.findContours return \"\n",
    "            \"signature yet again. Refer to OpenCV's documentation \"\n",
    "            \"in that case\"))\n",
    "\n",
    "    # return the actual contours array\n",
    "    return cnts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read image, resize and turn to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_crop_gray(im):\n",
    "    # Set image size to 1485x1050. Orig size 4676 × 3306.\n",
    "    # We must use fixed size, because we can not know size of \n",
    "    # the pics taken in the future and size is used in parameter tuning.\n",
    "    \n",
    "    # Size 2970x2100 2min\n",
    "    # Size 1485x1050 5sec\n",
    "    width = int(1485)\n",
    "    height = int(1050)\n",
    "    dim = (width, height)\n",
    "    im = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Cut out 50 border pixels from each side\n",
    "    im = im[50:, 50:]\n",
    "    im = im[:-50, :-50]\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Return color and grayscale images\n",
    "    return im, im_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read images\n",
    "\n",
    "Read two images. Uncomment two images you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read color image\n",
    "#image = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.09.15_033029_060_DYY.jpg', 1)\n",
    "\n",
    "# Hyde scanner1 example\n",
    "im1 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.22_033029_036_DYY.jpg', 1)\n",
    "im2 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.23_033029_037_DYY.jpg', 1)\n",
    "\n",
    "# Hyde scanner2 example\n",
    "#im1 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.16_033029_030_DYY.jpg', 1)\n",
    "#im1 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.17_033029_031_DYY.jpg', 1)\n",
    "#im2 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.18_033029_032_DYY.jpg', 1)\n",
    "\n",
    "# Varrio_Scanner2 example\n",
    "#im1 = cv2.imread('data/Varrio_Scanner2/VS2_T001_L001_2019.07.24_090749_132_DYY.jpg', 1)\n",
    "#im2 = cv2.imread('data/Varrio_Scanner2/VS2_T001_L001_2019.07.25_091204_133_DYY.jpg', 1)\n",
    "\n",
    "# Varrio Scanner3 example pairs\n",
    "#im1 = cv2.imread('data/Varrio_Scanner3/VS3_T001_L001_2018.08.05_033133_140_DYY.jpg', 1)\n",
    "#im2 = cv2.imread('data/Varrio_Scanner3/VS3_T001_L001_2018.08.06_033133_141_DYY.jpg', 1)\n",
    "\n",
    "# Normalize contrast\n",
    "im1 = cv2.normalize(im1, im1, 0, 255, cv2.NORM_MINMAX)\n",
    "im2 = cv2.normalize(im2, im2, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "# Get rescaled and cropped images in color and gray\n",
    "im1, im1_gray = scale_crop_gray(im1)\n",
    "im2, im2_gray = scale_crop_gray(im2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make light areas mask\n",
    "\n",
    "Filtering based on color. This is used as a prefiltering. The filtering find light areas that can be root or anything else. Edges are sharp, because no blurring is used, which would affect to the location of the root edges.\n",
    "\n",
    "After making light area filtering, we will remove isolated pixels that are smaller than a thershold.\n",
    "\n",
    "Input: one color image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_areas_mask_color(im):\n",
    "    \n",
    "    # Filter image by pixel values\n",
    "    mask = cv2.inRange(im, (112, 168,152),(254, 255,254))\n",
    "\n",
    "    # Remove isolated pixels\n",
    "    mask = remove_isolated_pixels(mask, min_size=40, max_size=50000)\n",
    "    \n",
    "    # \"Make areas fatter by 1 pixel (join roots where is holes in edges)\n",
    "    mask = cv2.dilate(mask, None, iterations=1)\n",
    "    \n",
    "    # Return results\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make edge areas mask (may be useless)\n",
    "\n",
    "Filtering based on edges\n",
    "\n",
    "Input: one grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_areas_mask(im_gray):\n",
    "    #thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "    #                               cv2.THRESH_BINARY_INV, 11, 7)\n",
    "    \n",
    "    # Blur with bilateralFilter. BilateralFilter does not blur edges.\n",
    "    blur = cv2.bilateralFilter(im_gray, 50, 15, 10)\n",
    "    \n",
    "    # Remove noise with gaussian blur\n",
    "    blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "    \n",
    "    # Find edges with canny edge detection\n",
    "    edges = cv2.Canny(blur, 50, 250)\n",
    "    \n",
    "    # \"Make areas fatter\" to fill missing pixels in root edges\n",
    "    edges = cv2.dilate(edges, None, iterations=2)\n",
    "    \n",
    "    # Get contrours\n",
    "    cnts = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = grab_contours(cnts)\n",
    "    \n",
    "    # Loop over our contours. Remove controus with area less than xxx.\n",
    "    contours=[]\n",
    "    for c in cnts:\n",
    "        size = cv2.contourArea(c)\n",
    "        if size > 20:\n",
    "            contours.append(c)\n",
    "    \n",
    "    # Make empty picture\n",
    "    empty = np.zeros(im_gray.shape, dtype = \"uint8\")\n",
    "    \n",
    "    # Save contours to empty image\n",
    "    contours = cv2.drawContours(empty, contours, -1, 255, -1)\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    # \"Make areas thinner\"\n",
    "    #change = cv2.erode(change, None, iterations=1)\n",
    "    # \"Make areas fatter\" to fill missing pixels in root edges\n",
    "    contours = cv2.dilate(contours, None, iterations=1)\n",
    "    \n",
    "    #Return contour areas\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make mask that finds differences between two images\n",
    "\n",
    "Filtering based on difference between two images\n",
    "\n",
    "Input: two color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_areas_mask(im1_color, im2_color):\n",
    "    \n",
    "    # Blur images\n",
    "    im1_color = cv2.bilateralFilter(im1_color, d=3, \n",
    "                                    sigmaColor=15, sigmaSpace=10)\n",
    "    im2_color = cv2.bilateralFilter(im2_color, d=3, \n",
    "                                    sigmaColor=15, sigmaSpace=10)\n",
    "    \n",
    "    # Calculate difference between images\n",
    "    diff = cv2.absdiff(im1_color, im2_color)\n",
    "    \n",
    "    # Save temp image\n",
    "    #cv2.imwrite('DIFFERENCE.png', diff)\n",
    "    \n",
    "    # Filter difference image by pixel values\n",
    "   # mask = cv2.inRange(diff, (10, 1, 20), (95, 85 ,90))\n",
    "    mask = cv2.inRange(diff, (10, 7, 17), (165, 170, 155))\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    mask = remove_isolated_pixels(mask, min_size=15, max_size=5000)\n",
    "    \n",
    "    # \"Make areas fatter\" to join areas\n",
    "    mask = cv2.dilate(mask, None, iterations=5)\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    # \"Make areas thinner\"\n",
    "    #change = cv2.erode(change, None, iterations=1)\n",
    "    \n",
    "\n",
    "    # Return results\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make circle around the found areas\n",
    "\n",
    "Input: mask and processed image with only root tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_circles_around(image, mask):\n",
    "    # find the contours in the mask, then sort them from left to right\n",
    "    cnts = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, \n",
    "                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cnts = grab_contours(cnts)\n",
    "    \n",
    "    # Sort contours from left to right\n",
    "    cnts = sort_contours(cnts)[0]\n",
    "    \n",
    "    # loop over the contours\n",
    "    for (i, c) in enumerate(cnts):\n",
    "    # draw the bright spot on the image\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        ((cX, cY), radius) = cv2.minEnclosingCircle(c)\n",
    "        cv2.circle(image, (int(cX), int(cY)), int(radius), (0, 255, 0), 2)\n",
    "        #cv2.putText(image, \"#{}\".format(i + 1), (x, y - 15), \n",
    "        #            cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, \n",
    "        #            color=(0, 255, 0), thickness=2)\n",
    "        \n",
    "    # Return image\n",
    "    return image, i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort contours by location\n",
    "\n",
    "Part of the function make_circles_around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "                                        key=lambda b: b[1][i], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return cnts, boundingBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove isolated pixels that have size less than thershold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_isolated_pixels(thresh, min_size, max_size):\n",
    "    # Perform a connected component analysis on the thresholded\n",
    "    # image and remove components that have size less than thershold\n",
    "    labels = measure.label(thresh, connectivity=2, background=0)\n",
    "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "    # loop over the unique components\n",
    "    for label in np.unique(labels):\n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask and count the\n",
    "        # number of pixels \n",
    "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        labelMask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero(labelMask)\n",
    "        # if the number of pixels in the component is sufficiently\n",
    "        # large, then add it to our mask of \"large blobs\"\n",
    "        if (numPixels > min_size) and (numPixels < max_size):\n",
    "            mask = cv2.add(mask, labelMask)\n",
    "            \n",
    "    # Return cleaned mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text(im, text):\n",
    "    # Set text font\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # Add text\n",
    "    cv2.putText(img=im, text=text, org=(50,900), fontFace=font, fontScale=2, \n",
    "                color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    # Return result\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print light and edge areas as binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get areas\n",
    "change_mask = change_areas_mask(im1, im2)\n",
    "#light_mask = light_areas_mask(im2_gray)\n",
    "light_mask = light_areas_mask_color(im2)\n",
    "edge_mask = edge_areas_mask(im2_gray)\n",
    "\n",
    "\n",
    "# Make supermask. Combine all masks.\n",
    "combined_mask = light_mask & change_mask\n",
    "\n",
    "# Remove noise from combined mask\n",
    "combined_mask = remove_isolated_pixels(combined_mask, min_size=40, max_size=5000)\n",
    "\n",
    "# From combined mask save only edges\n",
    "combined_mask_edges = cv2.Canny(combined_mask, 50, 250)\n",
    "\n",
    "# Concat gray, light_areas, edge_areas and change_areas to one image\n",
    "concat1 = np.concatenate((im2_gray, light_mask), axis=0)\n",
    "concat2 = np.concatenate((edge_mask, change_mask), axis=0)\n",
    "concat3 = np.concatenate((concat1, concat2), axis=0)\n",
    "concat4 = np.concatenate((concat3, combined_mask_edges), axis=0)\n",
    "\n",
    "# Save combined edges as own image for Olgas tests\n",
    "cv2.imwrite('edges_image.png', combined_mask_edges)\n",
    "\n",
    "# Save image\n",
    "#cv2.imwrite('Detect_roots_V2_binary.png', concat4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print images with colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask orig color image with mask (Add colors to images)\n",
    "light_areas = cv2.bitwise_or(im2, im2, mask=light_mask)\n",
    "#edge_areas = cv2.bitwise_or(im2, im2, mask=edge_mask)\n",
    "change_areas = cv2.bitwise_or(im2, im2, mask=change_mask)\n",
    "combined_areas = cv2.bitwise_or(im2, im2, mask=combined_mask)\n",
    "\n",
    "# Add circles around the roots and get number of contours (detected roots)\n",
    "im2, nbr_cnts = make_circles_around(im2, combined_mask)\n",
    "light_areas, nbr_cnts = make_circles_around(light_areas, combined_mask)\n",
    "#edge_areas, nbr_cnts = make_circles_around(edge_areas, combined_mask)\n",
    "change_areas, nbr_cnts = make_circles_around(change_areas, combined_mask)\n",
    "combined_areas, nbr_cnts = make_circles_around(combined_areas, combined_mask)\n",
    "\n",
    "# Add names to images\n",
    "im2 = add_text(im2, \"Original image. Number of roots :{}\".format(nbr_cnts))\n",
    "light_areas = add_text(light_areas, \"Color filter\")\n",
    "#edge_areas = add_text(edge_areas, \"Edge filter\")\n",
    "change_areas = add_text(change_areas, \"Change filter (pic2-pic1)\")\n",
    "combined_areas = add_text(combined_areas, \"Combined filter\")\n",
    "\n",
    "# Concat original, light_areas, edge_areas and change_areas to one image\n",
    "concat1 = np.concatenate((im2, light_areas), axis=0)\n",
    "#concat2 = np.concatenate((concat1, edge_areas), axis=0)\n",
    "concat2 = np.concatenate((concat1, change_areas), axis=0)\n",
    "concat3 = np.concatenate((concat2, combined_areas), axis=0)\n",
    "\n",
    "# Save images\n",
    "cv2.imwrite('Detect_roots_V2_color.png', concat3)\n",
    "cv2.imwrite('Detected_growth.png', im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
