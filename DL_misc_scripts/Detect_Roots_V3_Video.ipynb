{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create video of the images in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage import exposure, measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths and read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and video output name\n",
    "image_folder = 'data/Varrio_Scanner2'\n",
    "#image_folder = 'data/Hyde_Scanner1/2018'\n",
    "video_name = 'Video_Varrio2_V3.mp4'\n",
    "#video_name = 'Video_Hyde1_V3.mp4'\n",
    "\n",
    "# Number of pictures in second\n",
    "fps=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get image paths and set video settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image names\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "\n",
    "# Sort image names\n",
    "images = sorted(images)\n",
    "\n",
    "# Set video frame size to 2338x1653 (Scale = 0.5). Orig size 4676 × 3306.\n",
    "# We must use fixed size, because we can not know size of \n",
    "# the pics taken in the future and size is used in parameter tuning.\n",
    "width = int(1485)\n",
    "height = int(1050)\n",
    "dim_vid=(width, height*2)\n",
    "dim_pic=(width, height)\n",
    "\n",
    "# Set video settings\n",
    "video = cv2.VideoWriter(filename=video_name, fourcc=cv2.VideoWriter_fourcc(*'XVID'), fps=fps, frameSize=dim_vid)\n",
    "\n",
    "# Set text font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create only root images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect roots from image\n",
    "def light_areas_mask(img_color):\n",
    "    \n",
    "    # Filter image by pixel values\n",
    "    mask = cv2.inRange(im, (112, 168,152),(254, 255,254))\n",
    "\n",
    "    # Remove isolated pixels\n",
    "    mask = remove_isolated_pixels(mask, min_size=40, max_size=50000)\n",
    "    \n",
    "    # \"Make areas fatter by 1 pixel (join roots where is holes in edges)\n",
    "    mask = cv2.dilate(mask, None, iterations=1)\n",
    "    \n",
    "    # Return results\n",
    "    return mask\n",
    "\n",
    "def change_areas_mask(im1_color, im2_color):\n",
    "    # Blur images\n",
    "    im1_color = cv2.bilateralFilter(im1_color, d=3, \n",
    "                                    sigmaColor=15, sigmaSpace=10)\n",
    "    im2_color = cv2.bilateralFilter(im2_color, d=3, \n",
    "                                    sigmaColor=15, sigmaSpace=10)\n",
    "    \n",
    "    # Calculate difference between images\n",
    "    diff = cv2.absdiff(im1_color, im2_color)\n",
    "    \n",
    "    # Save temp image\n",
    "    cv2.imwrite('DIFFERENCE.png', diff)\n",
    "    \n",
    "    # Filter difference image by pixel values\n",
    "   # mask = cv2.inRange(diff, (10, 1, 20), (95, 85 ,90))\n",
    "    mask = cv2.inRange(diff, (10, 7, 17), (165, 170, 155))\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    mask = remove_isolated_pixels(mask, min_size=15, max_size=5000)\n",
    "    \n",
    "    # \"Make areas fatter\" to join areas\n",
    "    mask = cv2.dilate(mask, None, iterations=5)\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    # \"Make areas thinner\"\n",
    "    #change = cv2.erode(change, None, iterations=1)\n",
    "    \n",
    "\n",
    "    # Return results\n",
    "    return mask\n",
    "\n",
    "# Filter noise by the pixel area\n",
    "def remove_isolated_pixels(thresh, min_size, max_size):\n",
    "    # Perform a connected component analysis on the thresholded\n",
    "    # image and remove components that have size less than thershold\n",
    "    labels = measure.label(thresh, connectivity=2, background=0)\n",
    "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "    # loop over the unique components\n",
    "    for label in np.unique(labels):\n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask and count the\n",
    "        # number of pixels \n",
    "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        labelMask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero(labelMask)\n",
    "        # if the number of pixels in the component is sufficiently\n",
    "        # large, then add it to our mask of \"large blobs\"\n",
    "        if numPixels > min_size and numPixels < max_size:\n",
    "            mask = cv2.add(mask, labelMask)\n",
    "            \n",
    "    # Return cleaned mask\n",
    "    return mask\n",
    "\n",
    "def make_circles_around(image, mask):\n",
    "    # find the contours in the mask, then sort them from left to right\n",
    "    cnts, hierarchy = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, \n",
    "                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    i=0\n",
    "    # loop over the contours\n",
    "    for (i, c) in enumerate(cnts):\n",
    "    # draw the bright spot on the image\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        ((cX, cY), radius) = cv2.minEnclosingCircle(c)\n",
    "        # Tmp radius\n",
    "        radius=30\n",
    "        cv2.circle(image, (int(cX), int(cY)), int(radius), (0, 255, 0), 2)\n",
    "   \n",
    "    # Return image\n",
    "    return image, i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pics to video and save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [2:40:58<00:00, 52.49s/it]   \n"
     ]
    }
   ],
   "source": [
    "# Initialize roots locations binary array\n",
    "roots=np.zeros((height, width), np.uint8)\n",
    "\n",
    "# Make video of images. Use tqdm to see the progress.\n",
    "for i in tqdm(range(len(images))):\n",
    "    \n",
    "    # Get present day image name\n",
    "    image = images[i]\n",
    "    \n",
    "    if i==0:\n",
    "        # Read image\n",
    "        im = cv2.imread(os.path.join(image_folder, images[i]))\n",
    "        # Normalize image\n",
    "        im = cv2.normalize(im, im, 0, 255, cv2.NORM_MINMAX)\n",
    "        # Resize image\n",
    "        im = cv2.resize(im, dim_pic,interpolation = cv2.INTER_AREA)\n",
    "        # Get new root location pixels\n",
    "        new_roots=light_areas_mask(im)\n",
    "        # Add new root locations pixels to previous root locations pixels\n",
    "        roots = new_roots+roots\n",
    "        \n",
    "    else:\n",
    "        # Read images\n",
    "        im_yesterday = cv2.imread(os.path.join(image_folder, images[i-1]))\n",
    "        im = cv2.imread(os.path.join(image_folder, images[i]))\n",
    "        \n",
    "        # Normalize image\n",
    "        im_yesterday = cv2.normalize(im_yesterday, im_yesterday, 0, 255, cv2.NORM_MINMAX)\n",
    "        im = cv2.normalize(im, im, 0, 255, cv2.NORM_MINMAX)\n",
    "        \n",
    "        # Resize images\n",
    "        im_yesterday = cv2.resize(im_yesterday, dim_pic, interpolation = cv2.INTER_AREA)\n",
    "        im = cv2.resize(im, dim_pic, interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        # Get new root location pixels\n",
    "        light_mask = light_areas_mask(im)\n",
    "        change_mask = change_areas_mask(im_yesterday, im)\n",
    "        new_roots = light_mask & change_mask\n",
    "        \n",
    "        # Remove noise from mask\n",
    "        new_roots = remove_isolated_pixels(new_roots, min_size=40, max_size=5000)\n",
    "\n",
    "        # Add new root locations pixels to previous root locations pixels\n",
    "        roots = new_roots+roots\n",
    "        \n",
    "    # Mask root locations to image (get colors to root pixels)\n",
    "    im_masked = cv2.bitwise_or(im, im, mask=roots)\n",
    "    \n",
    "    # Make circle around the new root tips\n",
    "    im, nbr_cnts = make_circles_around(im, new_roots)\n",
    "    \n",
    "    # Add number of roots to lower corner\n",
    "    cv2.putText(img=im_masked, text=\"Found growth in {} roots\".format(nbr_cnts), org=(50,1000), \n",
    "                fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2, \n",
    "                color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    \n",
    "    # Concat original image and roots image vertically\n",
    "    im = np.concatenate((im, im_masked), axis=0)\n",
    "    \n",
    "    # Get image date from the image name\n",
    "    # Date is in different location for Hyde and Varrio\n",
    "    #date = image[20:30] # For Hyde Scanners\n",
    "    date = image[14:24] # For Varrio Scanners\n",
    "    \n",
    "    # Add date to upper left corner\n",
    "    cv2.putText(img=im, text=date, org=(30, 90), fontFace=font, \n",
    "                fontScale=2, color=(255, 255, 255), thickness=2, \n",
    "                lineType=cv2.LINE_AA)\n",
    "    \n",
    "    # Add frame to video\n",
    "    video.write(im)\n",
    "     \n",
    "# Close windows\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "# Save output video\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
