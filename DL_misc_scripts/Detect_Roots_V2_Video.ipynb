{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create video of the images in the folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage import exposure, measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set paths and read images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set paths and video output name\n",
    "image_folder = 'data/Varrio_Scanner2'\n",
    "video_name = 'Video_Varrio2_V2.mp4'\n",
    "\n",
    "# Number of pictures in second\n",
    "fps=3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get image paths and set video settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get image names\n",
    "images = [img for img in os.listdir(image_folder) if img.endswith(\".jpg\")]\n",
    "\n",
    "# Sort image names\n",
    "images = sorted(images)\n",
    "\n",
    "# Set video frame size to 2338x1653 (Scale = 0.5). Orig size 4676 × 3306.\n",
    "# We must use fixed size, because we can not know size of \n",
    "# the pics taken in the future and size is used in parameter tuning.\n",
    "width = int(1485)\n",
    "height = int(1050)\n",
    "dim_vid=(width, height*2)\n",
    "dim_pic=(width, height)\n",
    "\n",
    "# Set video settings\n",
    "video = cv2.VideoWriter(filename=video_name, fourcc=cv2.VideoWriter_fourcc(*'XVID'), fps=fps, frameSize=dim_vid)\n",
    "\n",
    "# Set text font\n",
    "font = cv2.FONT_HERSHEY_SIMPLEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create only root images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect roots from image\n",
    "def light_areas_mask(img_color):\n",
    "    \n",
    "    # Filter image by pixel values\n",
    "    mask = cv2.inRange(im, (112, 168,152),(254, 255,254))\n",
    "\n",
    "    # Remove isolated pixels\n",
    "    mask = remove_isolated_pixels(mask, min_size=40, max_size=50000)\n",
    "    \n",
    "    # \"Make areas fatter by 1 pixel (join roots where is holes in edges)\n",
    "    mask = cv2.dilate(mask, None, iterations=1)\n",
    "    \n",
    "    # Return results\n",
    "    return mask\n",
    "\n",
    "\n",
    "\n",
    "# Filter noise by the pixel area\n",
    "def remove_isolated_pixels(thresh, min_size, max_size):\n",
    "    # Perform a connected component analysis on the thresholded\n",
    "    # image and remove components that have size less than thershold\n",
    "    labels = measure.label(thresh, connectivity=2, background=0)\n",
    "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "    # loop over the unique components\n",
    "    for label in np.unique(labels):\n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask and count the\n",
    "        # number of pixels \n",
    "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        labelMask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero(labelMask)\n",
    "        # if the number of pixels in the component is sufficiently\n",
    "        # large, then add it to our mask of \"large blobs\"\n",
    "        if numPixels > min_size and numPixels < max_size:\n",
    "            mask = cv2.add(mask, labelMask)\n",
    "            \n",
    "    # Return cleaned mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert pics to video and save output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 184/184 [12:46<00:00,  4.16s/it]\n"
     ]
    }
   ],
   "source": [
    "# Initialize roots locations binary array\n",
    "roots=np.zeros((height, width), np.uint8)\n",
    "\n",
    "# Make video of images. Use tqdm to see the progress.\n",
    "for i in tqdm(range(len(images))):\n",
    "    \n",
    "    # Print image name\n",
    "    image = images[i]\n",
    "    \n",
    "    # Read image\n",
    "    im = cv2.imread(os.path.join(image_folder, images[i]))\n",
    "    \n",
    "    # Normalize image\n",
    "    im = cv2.normalize(im, im, 0, 255, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Resize image\n",
    "    im = cv2.resize(im, dim_pic,interpolation = cv2.INTER_AREA)\n",
    "     \n",
    "    # Get new root location pixels\n",
    "    new_roots=light_areas_mask(im)\n",
    "    \n",
    "    # Add new root locations pixels to previous root locations pixels\n",
    "    roots = new_roots+roots\n",
    "    \n",
    "    # Mask root locations to image (get colors to root pixels)\n",
    "    im_masked = cv2.bitwise_or(im, im, mask=roots)\n",
    "    \n",
    "    # Concat original image and roots image vertically\n",
    "    im = np.concatenate((im, im_masked), axis=0)\n",
    "    \n",
    "    # Get image date from the image name\n",
    "    # Date is in different location for Hyde and Varrio\n",
    "    #date = image[20:30] # For Hyde Scanners\n",
    "    date = image[14:24] # For Varrio Scanners\n",
    "    \n",
    "    # Add date to upper left corner\n",
    "    cv2.putText(img=im, text=date, org=(30, 90), fontFace=font, fontScale=2, \n",
    "                color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    # Add frame to video\n",
    "    video.write(im)\n",
    "     \n",
    "# Close windows\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "# Save output video\n",
    "video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}