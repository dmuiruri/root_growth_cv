{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Root detection\n",
    "\n",
    "In this notebook I will test different masking techniques to make image segmentation so that roots can be separated from the background."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reset notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from skimage import exposure, measure\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read image, resize and turn to gray scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_crop_gray(im):\n",
    "    # Set image size to 1485x1050. Orig size 4676 × 3306.\n",
    "    # We must use fixed size, because we can not know size of \n",
    "    # the pics taken in the future and size is used in parameter tuning.\n",
    "    \n",
    "    # Size 2970x2100 2min\n",
    "    # Size 1485x1050 5sec\n",
    "    width = int(1485)\n",
    "    height = int(1050)\n",
    "    dim = (width, height)\n",
    "    im = cv2.resize(im, dim, interpolation = cv2.INTER_AREA)\n",
    "    \n",
    "    # Cut out 50 border pixels from each side\n",
    "    #im = im[50:, 50:]\n",
    "    #im = im[:-50, :-50]\n",
    "    \n",
    "    # Convert the image to grayscale\n",
    "    im_gray = cv2.cvtColor(im, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Return color and grayscale images\n",
    "    return im, im_gray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read images\n",
    "\n",
    "Read two images. Uncomment two images you want to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read color image\n",
    "#image = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.09.15_033029_060_DYY.jpg', 1)\n",
    "\n",
    "# Hyde scanner1 example\n",
    "#im1 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.16_033029_030_DYY.jpg', 1)\n",
    "#im2 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.23_033029_037_DYY.jpg', 1)\n",
    "\n",
    "# Hyde scanner2 example\n",
    "im1 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.16_033029_030_DYY.jpg', 1)\n",
    "im2 = cv2.imread('data/Hyde_scanner1/hydescan1_T001_L001_2018.08.17_033029_031_DYY.jpg', 1)\n",
    "\n",
    "# Varrio_Scanner2 example\n",
    "#im1 = cv2.imread('data/Varrio_Scanner2/VS2_T001_L001_2019.07.24_090749_132_DYY.jpg', 1)\n",
    "#im2 = cv2.imread('data/Varrio_Scanner2/VS2_T001_L001_2019.07.25_091204_133_DYY.jpg', 1)\n",
    "\n",
    "# Varrio Scanner3 example pairs\n",
    "#im1 = cv2.imread('data/Varrio_Scanner3/VS3_T001_L001_2018.08.05_033133_140_DYY.jpg', 1)\n",
    "#im2 = cv2.imread('data/Varrio_Scanner3/VS3_T001_L001_2018.08.06_033133_141_DYY.jpg', 1)\n",
    "\n",
    "# Get rescaled and cropped images in color and gray\n",
    "im1, im1_gray = scale_crop_gray(im1)\n",
    "im2, im2_gray = scale_crop_gray(im2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make light areas mask\n",
    "\n",
    "Filtering based on color. This is used as a prefiltering. The filtering find light areas that can be root or anything else. Edges are sharp, because no blurring is used, which would affect to the location of the root edges.\n",
    "\n",
    "After making light area filtering, we will remove isolated pixels that are smaller than a thershold.\n",
    "\n",
    "Input: one grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def light_areas_mask(im_gray):\n",
    "    \n",
    "    # Threshold image by color (remove dark areas) (180 and 250)\n",
    "    ret, thresh = cv2.threshold(im_gray,190,256,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Smooth edges\n",
    "    #\"Make areas thinner\"\n",
    "    thresh = cv2.erode(thresh, None, iterations=1)\n",
    "    # \"Make areas fatter\"\n",
    "    thresh = cv2.dilate(thresh, None, iterations=1)\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    mask = remove_isolated_pixels(thresh, min_size=130, max_size=1800)\n",
    "    \n",
    "    # Return results\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make edge areas mask (may be useless)\n",
    "\n",
    "Filtering based on edges\n",
    "\n",
    "Input: one grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_areas_mask(im_gray):\n",
    "    #thresh = cv2.adaptiveThreshold(image, 255, cv2.ADAPTIVE_THRESH_MEAN_C, \n",
    "    #                               cv2.THRESH_BINARY_INV, 11, 7)\n",
    "    \n",
    "    # Blur with bilateralFilter. BilateralFilter does not blur edges.\n",
    "    blur = cv2.bilateralFilter(im_gray, 50, 15, 10)\n",
    "    \n",
    "    # Remove noise with gaussian blur\n",
    "    blur = cv2.GaussianBlur(blur,(5,5),0)\n",
    "    \n",
    "    # Find edges with canny edge detection\n",
    "    edges = cv2.Canny(blur, 50, 250)\n",
    "    \n",
    "    # \"Make areas fatter\" to fill missing pixels in root edges\n",
    "    edges = cv2.dilate(edges, None, iterations=2)\n",
    "    \n",
    "    # Get contrours\n",
    "    cnts, hierarchy = cv2.findContours(edges, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Loop over our contours. Remove controus with area less than xxx.\n",
    "    contours=[]\n",
    "    for c in cnts:\n",
    "        size = cv2.contourArea(c)\n",
    "        if size > 20:\n",
    "            contours.append(c)\n",
    "    \n",
    "    # Make empty picture\n",
    "    empty = np.zeros(im_gray.shape, dtype = \"uint8\")\n",
    "    \n",
    "    # Save contours to empty image\n",
    "    contours = cv2.drawContours(empty, contours, -1, 255, -1)\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    # \"Make areas thinner\"\n",
    "    #change = cv2.erode(change, None, iterations=1)\n",
    "    # \"Make areas fatter\" to fill missing pixels in root edges\n",
    "    contours = cv2.dilate(contours, None, iterations=1)\n",
    "    \n",
    "    #Return contour areas\n",
    "    return contours"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make mask that finds differences between two images\n",
    "\n",
    "Filtering based on difference between two images\n",
    "\n",
    "Input: two color images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_areas_mask(im1_color, im2_color):\n",
    "    \n",
    "    # Calculate difference between images\n",
    "    diff = cv2.absdiff(im1_color, im2_color)\n",
    "    \n",
    "    # Convert color difference image to gray\n",
    "    mask = cv2.cvtColor(diff, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Threshold and turn to binary\n",
    "    ret, change = cv2.threshold(mask,55,256,cv2.THRESH_BINARY)\n",
    "    \n",
    "    # \"Make areas fatter\"\n",
    "    change = cv2.dilate(change, None, iterations=1)\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    change = remove_isolated_pixels(change, min_size=160, max_size=1800)\n",
    "    \n",
    "    # Remove isolated pixels\n",
    "    # \"Make areas thinner\"\n",
    "    change = cv2.erode(change, None, iterations=1)\n",
    "    # \"Make areas fatter\"\n",
    "    change = cv2.dilate(change, None, iterations=3)\n",
    "\n",
    "    # Return results\n",
    "    return change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make circle around the found areas\n",
    "\n",
    "Input: mask and processed image with only root tips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_circles_around(image, mask):\n",
    "    # find the contours in the mask, then sort them from left to right\n",
    "    cnts, hierarchy = cv2.findContours(mask.copy(), cv2.RETR_EXTERNAL, \n",
    "                            cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Sort contours from left to right\n",
    "    cnts = sort_contours(cnts)[0]\n",
    "    \n",
    "    # loop over the contours\n",
    "    for (i, c) in enumerate(cnts):\n",
    "    # draw the bright spot on the image\n",
    "        (x, y, w, h) = cv2.boundingRect(c)\n",
    "        ((cX, cY), radius) = cv2.minEnclosingCircle(c)\n",
    "        cv2.circle(image, (int(cX), int(cY)), int(radius), (0, 255, 0), 3)\n",
    "        cv2.putText(image, \"#{}\".format(i + 1), (x, y - 15), \n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, fontScale=1, \n",
    "                    color=(0, 255, 0), thickness=2)\n",
    "        \n",
    "    # Return image\n",
    "    return image, i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sort contours by location\n",
    "\n",
    "Part of the function make_circles_around"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_contours(cnts, method=\"left-to-right\"):\n",
    "    # initialize the reverse flag and sort index\n",
    "    reverse = False\n",
    "    i = 0\n",
    "\n",
    "    # handle if we need to sort in reverse\n",
    "    if method == \"right-to-left\" or method == \"bottom-to-top\":\n",
    "        reverse = True\n",
    "\n",
    "    # handle if we are sorting against the y-coordinate rather than\n",
    "    # the x-coordinate of the bounding box\n",
    "    if method == \"top-to-bottom\" or method == \"bottom-to-top\":\n",
    "        i = 1\n",
    "\n",
    "    # construct the list of bounding boxes and sort them from top to\n",
    "    # bottom\n",
    "    boundingBoxes = [cv2.boundingRect(c) for c in cnts]\n",
    "    (cnts, boundingBoxes) = zip(*sorted(zip(cnts, boundingBoxes),\n",
    "                                        key=lambda b: b[1][i], reverse=reverse))\n",
    "\n",
    "    # return the list of sorted contours and bounding boxes\n",
    "    return cnts, boundingBoxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove isolated pixels that have size less than thershold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_isolated_pixels(thresh, min_size, max_size):\n",
    "    # Perform a connected component analysis on the thresholded\n",
    "    # image and remove components that have size less than thershold\n",
    "    labels = measure.label(thresh, connectivity=2, background=0)\n",
    "    mask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "    # loop over the unique components\n",
    "    for label in np.unique(labels):\n",
    "        # if this is the background label, ignore it\n",
    "        if label == 0:\n",
    "            continue\n",
    "        # otherwise, construct the label mask and count the\n",
    "        # number of pixels \n",
    "        labelMask = np.zeros(thresh.shape, dtype=\"uint8\")\n",
    "        labelMask[labels == label] = 255\n",
    "        numPixels = cv2.countNonZero(labelMask)\n",
    "        # if the number of pixels in the component is sufficiently\n",
    "        # large, then add it to our mask of \"large blobs\"\n",
    "        if numPixels > min_size and numPixels < max_size:\n",
    "            mask = cv2.add(mask, labelMask)\n",
    "            \n",
    "    # Return cleaned mask\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add text to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_text(im, text):\n",
    "    # Set text font\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "    # Add text\n",
    "    cv2.putText(img=im, text=text, org=(50,1000), fontFace=font, fontScale=2, \n",
    "                color=(255, 255, 255), thickness=2, lineType=cv2.LINE_AA)\n",
    "    \n",
    "    # Return result\n",
    "    return im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print light and edge areas as binary masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get areas\n",
    "change_mask = change_areas_mask(im1, im2)\n",
    "light_mask = light_areas_mask(im2_gray)\n",
    "edge_mask = edge_areas_mask(im2_gray)\n",
    "\n",
    "\n",
    "# Make supermask. Combine all masks.\n",
    "combined_mask = light_mask & change_mask\n",
    "\n",
    "# Concat gray, light_areas, edge_areas and change_areas to one image\n",
    "concat1 = np.concatenate((im1_gray, light_mask), axis=0)\n",
    "concat2 = np.concatenate((edge_mask, change_mask), axis=0)\n",
    "concat3 = np.concatenate((concat1, concat2), axis=0)\n",
    "concat4 = np.concatenate((concat3, combined_mask), axis=0)\n",
    "\n",
    "# Save image\n",
    "cv2.imwrite('Detect_roots_V2.png', concat4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print images with colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mask orig color image with mask (Add colors to images)\n",
    "light_areas = cv2.bitwise_or(im2, im2, mask=light_mask)\n",
    "edge_areas = cv2.bitwise_or(im2, im2, mask=edge_mask)\n",
    "change_areas = cv2.bitwise_or(im2, im2, mask=change_mask)\n",
    "combined_areas = cv2.bitwise_or(im2, im2, mask=combined_mask)\n",
    "\n",
    "# Add circles around the roots and get number of contours (detected roots)\n",
    "im2, nbr_cnts = make_circles_around(im2, combined_mask)\n",
    "light_areas, nbr_cnts = make_circles_around(light_areas, combined_mask)\n",
    "edge_areas, nbr_cnts = make_circles_around(edge_areas, combined_mask)\n",
    "change_areas, nbr_cnts = make_circles_around(change_areas, combined_mask)\n",
    "combined_areas, nbr_cnts = make_circles_around(combined_areas, combined_mask)\n",
    "\n",
    "# Add names to images\n",
    "im2 = add_text(im2, \"Original image. Number of roots :{}\".format(nbr_cnts))\n",
    "light_areas = add_text(light_areas, \"Color filter\")\n",
    "edge_areas = add_text(edge_areas, \"Edge filter\")\n",
    "change_areas = add_text(change_areas, \"Change filter (pic2-pic1)\")\n",
    "combined_areas = add_text(combined_areas, \"Combined filter\")\n",
    "\n",
    "# Concat original, light_areas, edge_areas and change_areas to one image\n",
    "concat1 = np.concatenate((im2, light_areas), axis=0)\n",
    "concat2 = np.concatenate((edge_areas, change_areas), axis=0)\n",
    "concat3 = np.concatenate((concat1, concat2), axis=0)\n",
    "concat4 = np.concatenate((concat3, combined_areas), axis=0)\n",
    "\n",
    "# Show image\n",
    "#cv2.imshow(\"imgages\", vertical_concat)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "\n",
    "# Save images grayscale\n",
    "cv2.imwrite('Detect_roots_V2_color.png', concat4)\n",
    "cv2.imwrite('Detected_tips.png', im2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
